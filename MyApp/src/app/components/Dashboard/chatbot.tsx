import React, { useState, useRef, useEffect, useCallback } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  FlatList,
  StyleSheet,
  KeyboardAvoidingView,
  Platform,
  ActivityIndicator,
  Alert,
  ImageBackground,
  Animated,
  Modal,
  Image
} from 'react-native';
import { Ionicons, EvilIcons } from '@expo/vector-icons';
import { useRouter } from 'expo-router';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';
import * as ImagePicker from 'expo-image-picker';
import * as MediaLibrary from 'expo-media-library';
import Groq from "groq-sdk";
import { useAuth } from "../../hooks/useAuth";
import { useTransactionContext } from '../../contexts/TransactionContext';
import {
  initializeChatHistory,
  getChatHistory,
  updateChatHistory,
  saveExpenseToCSV,
  getExpensesFromCSV,
  analyzeTimeRange,
  getDailyExpenses,
  getMonthlyExpenses,
  getQuarterlyExpenses,
  getYearlyExpenses,
  getRecentMessages
} from '../../../services/firebase/storage';

interface Expense {
  timestamp: string;
  type: string;
  category: string;
  amount: string;
  title: string;
}

// Add these missing helper functions to filter expenses by date/month:
async function getExpensesForDate(userId: string, date: Date): Promise<Expense[]> {
  const allExpenses = await getExpensesFromCSV(userId);
  return allExpenses.filter(exp => {
    const expDate = new Date(exp.timestamp);
    return expDate.toDateString() === date.toDateString();
  });
}

async function getExpensesForMonth(userId: string, year: number, month: number): Promise<Expense[]> {
  const allExpenses = await getExpensesFromCSV(userId);
  return allExpenses.filter(exp => {
    const expDate = new Date(exp.timestamp);
    return expDate.getFullYear() === year && (expDate.getMonth() + 1) === month;
  });
}

// Kh·ªüi t·∫°o Groq
const groq = new Groq({
  apiKey: "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",
  dangerouslyAllowBrowser: true
});

const baseSystemPrompt = `B·∫°n l√† tr·ª£ l√Ω t√†i ch√≠nh th√¥ng minh, nhi·ªám v·ª• ch√≠nh l√† gi√∫p ng∆∞·ªùi d√πng theo d√µi thu chi. H√£y ph√¢n t√≠ch v√† ph·∫£n h·ªìi ng·∫Øn g·ªçn,  s√∫c t√≠ch.
PH√ÇN LO·∫†I:
THU NH·∫¨P:
- L∆∞∆°ng th√°ng: l∆∞∆°ng, th∆∞·ªüng c√¥ng vi·ªác
- Ti·∫øt ki·ªám: l√£i su·∫•t, ƒë·∫ßu t∆∞
- Kh√°c: qu√†, ti·ªÅn m·ª´ng, th∆∞·ªüng
CHI TI√äU:
- ƒÇn u·ªëng:
- Y t·∫ø: thu·ªëc
- Mua s·∫Øm:s√†n th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠
- Di chuy·ªÉn: xƒÉng,du l·ªãch  
- H√≥a ƒë∆°n:
- Gi·∫£i tr√≠: phim, game
- Gi√°o d·ª•c: h·ªçc ph√≠, s√°ch v·ªü
- ƒê·∫ßu t∆∞: ch·ª©ng kho√°n, ti·∫øt ki·ªám
- Kh√°c: chi ph√≠ ph√°t sinh
Output format: 
**Ph√¢n lo·∫°i: [category], Ti·ªÅn: [amount] VNƒê, Ti√™u ƒë·ªÅ: [short_title]** sau ph·∫ßn n√†y l√† th√™m l·ªùi vƒÉn c·ªßa b·∫°n cho ng∆∞·ªùi d√πng n·∫øu th·∫•y kho·∫£ng chi h·ª£p l√≠ th√¨ sao ƒë√≥ t√πy b·∫°n c√≤n n·∫øu th·∫•y kh√¥ng h·ª£p l√Ω th√¨ ch·ª≠i ng∆∞·ªùi d√πng cho t√¥i.
V·ªõi c√¢u h·ªèi kh√¥ng li√™n quan t√†i ch√≠nh: Tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán.`;

interface Message {
  id: string;
  text: string;
  isUser: boolean;
  timestamp: Date;
}

interface TranscriptionResponse {
  text: string;
  x_groq: {
    id: string;
  };
}

const Chatbot: React.FC = () => {
  const router = useRouter();
  const { user } = useAuth();
  const { refreshTransactions } = useTransactionContext();

  const [messages, setMessages] = useState<Message[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [isLoadingHistory, setIsLoadingHistory] = useState(true);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [pressStartTime, setPressStartTime] = useState<number>(0);
  const [isLongPress, setIsLongPress] = useState(false);
  const [recordingMode, setRecordingMode] = useState<'tap' | 'hold' | null>(null);

  const flatListRef = useRef<FlatList>(null);
  const recordingRef = useRef<Audio.Recording | null>(null);
  const durationTimer = useRef<ReturnType<typeof setInterval> | null>(null);
  const longPressTimeout = useRef<NodeJS.Timeout>();

  const amplitudes = useRef([...Array(15)].map(() => new Animated.Value(1))).current;
  const [waveData, setWaveData] = useState<number[]>(Array(15).fill(1));
  const animationFrameId = useRef<number>();
  const [awaitingPriceInput, setAwaitingPriceInput] = useState(false);
  const [tempProductInfo, setTempProductInfo] = useState<{
  type: string;
  category: string;
} | null>(null);

  const updateWaveData = useCallback(() => {
    if (isRecording) {
      const newAmplitude = (Math.random() * 0.5) + 0.75;
      setWaveData(prevData => {
        const newData = [...prevData.slice(1), newAmplitude];
        return newData;
      });

      animationFrameId.current = requestAnimationFrame(updateWaveData);
    }
  }, [isRecording]);

  useEffect(() => {
    if (isRecording) {
      setWaveData(Array(15).fill(1));
      animationFrameId.current = requestAnimationFrame(updateWaveData);
    } else {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
      setWaveData(Array(15).fill(1));
    }

    return () => {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
    };
  }, [isRecording, updateWaveData]);

  useEffect(() => {
    if (isRecording) {
      setRecordingDuration(0);
      durationTimer.current = setInterval(() => {
        setRecordingDuration(prev => prev + 1);
      }, 1000);
    } else {
      if (durationTimer.current) {
        clearInterval(durationTimer.current);
        durationTimer.current = null;
      }
      setRecordingDuration(0);
    }

    return () => {
      if (durationTimer.current) {
        clearInterval(durationTimer.current);
      }
    };
  }, [isRecording]);

  useEffect(() => {
    const loadChatHistory = async () => {
      if (!user) return;

      setIsLoadingHistory(true);
      try {
        const welcomeMessage: Message = {
          id: '1',
          text: 'Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?',
          isUser: false,
          timestamp: new Date()
        };

        await initializeChatHistory(user.uid, welcomeMessage);
        const history = await getChatHistory(user.uid);
        if (history.length > 0) {
          setMessages(history);
        } else {
          setMessages([welcomeMessage]);
        }
      } catch (error) {
        console.error('Error loading chat history:', error);
        Alert.alert('Error', 'Kh√¥ng th·ªÉ t·∫£i l·ªãch s·ª≠ chat');
        setMessages([{
          id: '1',
          text: 'Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?',
          isUser: false,
          timestamp: new Date()
        }]);
      } finally {
        setIsLoadingHistory(false);
      }
    };

    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Timeout')), 10000);
    });

    Promise.race([loadChatHistory(), timeoutPromise])
      .catch(error => {
        if (error.message === 'Timeout') {
          setIsLoadingHistory(false);
          setMessages([{
            id: '1',
            text: 'Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?',
            isUser: false,
            timestamp: new Date()
          }]);
          Alert.alert('Th√¥ng b√°o', 'T·∫£i l·ªãch s·ª≠ chat qu√° l√¢u, ƒë√£ chuy·ªÉn mode m·ªõi.');
        }
      });
  }, [user]);

  const getCSVString = async (userId: string): Promise<string> => {
    try {
      const expenses = await getExpensesFromCSV(userId);
      return JSON.stringify(expenses, null, 2);
    } catch (error) {
      console.error("L·ªói khi l·∫•y d·ªØ li·ªáu CSV:", error);
      return "Kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung chi_tieu.csv";
    }
  };

  const getDailyChatHistoryString = async (userId: string): Promise<string> => {
    try {
      const dailyMessages = await getChatHistory(userId);
      return JSON.stringify(dailyMessages, null, 2);
    } catch (error) {
      console.error("L·ªói l·∫•y chat history ng√†y h√¥m nay:", error);
      return "Kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c l·ªãch s·ª≠ chat ng√†y h√¥m nay";
    }
  };

  const sendMessageByVoice = async (transcribedText: string) => {
    if (!transcribedText.trim() || isLoading || !user) return;
  
    // N·∫øu ƒëang ch·ªù input gi√° ti·ªÅn
    if (awaitingPriceInput && tempProductInfo) {
      // X·ª≠ l√Ω text ƒë·ªÉ l·∫•y s·ªë ti·ªÅn
      const amount = transcribedText.replace(/[^0-9]/g, '');
      
      if (amount) {
        try {
          await saveExpenseToCSV(user.uid, {
            category: tempProductInfo.category,
            amount: amount,
            title: tempProductInfo.type,
            type: 'expense',
            timestamp: new Date().toISOString()
          });
          refreshTransactions();
          
          const confirmMessage: Message = {
            id: Date.now().toString(),
            text: `**Ph√¢n lo·∫°i: ${tempProductInfo.category}, Ti·ªÅn: ${amount} VNƒê, Ti√™u ƒë·ªÅ: ${tempProductInfo.type}** ƒê√£ ghi nh·∫≠n kho·∫£n chi c·ªßa b·∫°n.`,
            isUser: false,
            timestamp: new Date(),
          };
  
          const updatedMessages = [...messages, confirmMessage];
          setMessages(updatedMessages);
          await updateChatHistory(user.uid, updatedMessages);
  
        } catch (error) {
          console.error('Error saving expense:', error);
          Alert.alert('Error', 'Kh√¥ng th·ªÉ l∆∞u chi ti√™u. Vui l√≤ng th·ª≠ l·∫°i.');
        }
  
        // Reset states
        setAwaitingPriceInput(false);
        setTempProductInfo(null);
        return;
      }
    }
    
    const handleUserQuestion = async (question: string) => {
      const timeRange = analyzeTimeRange(question);
      let expenses: Expense[] = [];
      const isSummaryRequest = question.toLowerCase().includes('t·ªïng') || 
                              question.toLowerCase().includes('bao nhi√™u') ||
                              question.toLowerCase().includes('chi ti√™u') ||
                              timeRange.type !== 'none';
  
      try {
        // N·∫øu l√† c√¢u h·ªèi t·ªïng h·ª£p/th·ªëng k√™
        if (isSummaryRequest) {
          switch (timeRange.type) {
            case 'day':
              if (timeRange.date) {
                expenses = await getDailyExpenses(user.uid, timeRange.date);
              }
              break;
            case 'month':
              if (timeRange.year && timeRange.month) {
                expenses = await getMonthlyExpenses(user.uid, timeRange.year, timeRange.month);
              }
              break;
            case 'quarter':
              if (timeRange.year && timeRange.quarter) {
                expenses = await getQuarterlyExpenses(user.uid, timeRange.year, timeRange.quarter);
              }
              break;
            case 'year':
              if (timeRange.year) {
                expenses = await getYearlyExpenses(user.uid, timeRange.year);
              }
              break;
            default:
              // M·∫∑c ƒë·ªãnh l·∫•y chi ti√™u ng√†y hi·ªán t·∫°i
              expenses = await getDailyExpenses(user.uid, new Date());
          }
        } else {
          // N·∫øu l√† c√¢u h·ªèi th√¥ng th∆∞·ªùng, ch·ªâ l·∫•y chi ti√™u c·ªßa ng√†y
          expenses = await getDailyExpenses(user.uid, new Date());
        }
        return { expenses, isSummaryRequest };
      } catch (error) {
        console.error('Error getting expenses:', error);
        return { expenses: [], isSummaryRequest };
      }
    };
  
    const userMessage: Message = {
      id: Date.now().toString(),
      text: transcribedText.trim(),
      isUser: true,
      timestamp: new Date(),
    };
    
    const updatedMessages = [...messages, userMessage];
    setMessages(updatedMessages);
    setIsLoading(true);
  
    try {
      // L·∫•y 2 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ c√≥ context
      const recentMessages = await getRecentMessages(user.uid, 2);
      const { expenses, isSummaryRequest } = await handleUserQuestion(transcribedText);
  
      // T·∫°o prompt kh√°c nhau cho c√¢u h·ªèi th√¥ng th∆∞·ªùng v√† c√¢u h·ªèi t·ªïng h·ª£p
      let systemPromptWithData;
      if (isSummaryRequest) {
        systemPromptWithData = `
        B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o d·ªØ li·ªáu chi ti√™u (·ªü d·∫°ng JSON):
        ${JSON.stringify(expenses, null, 2)}
  
        H√£y ph√¢n t√≠ch v√† t·ªïng h·ª£p chi ti√™u m·ªôt c√°ch tr·ª±c quan, d·ªÖ hi·ªÉu.
        V·ªõi c√¢u h·ªèi t·ªïng h·ª£p/th·ªëng k√™, h·ªèi ƒë·∫Øt hay r·∫ª KH√îNG s·ª≠ d·ª•ng format ** ** m√† h√£y tr√¨nh b√†y theo d·∫°ng:
        - T·ªïng thu: xxx
        - T·ªïng chi: xxx
        - Chi ti·∫øt theo danh m·ª•c: (n·∫øu c√≥)
          + Danh m·ª•c 1: xxx
          + Danh m·ª•c 2: xxx
        - Nh·∫≠n x√©t v√† g√≥p √Ω v·ªÅ t√¨nh h√¨nh chi ti√™u
        `;
      } else {
        systemPromptWithData = `
        B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o d·ªØ li·ªáu chi ti√™u h√¥m nay (·ªü d·∫°ng JSON):
        ${JSON.stringify(expenses, null, 2)}
  
        Tin nh·∫Øn g·∫ßn nh·∫•t:
        ${recentMessages.map(msg => `${msg.isUser ? 'User' : 'Bot'}: ${msg.text}`).join('\n')}
  
        ${baseSystemPrompt}
        `;
      }
  
      const completion = await groq.chat.completions.create({
        messages: [
          { role: 'system', content: systemPromptWithData },
          { role: 'user', content: userMessage.text }
        ],
        model: "qwen-2.5-32b",
        temperature: 0.5,
        max_tokens: 1024,
      });
  
      const responseText = completion.choices[0]?.message?.content || "";
      console.log("Bot response:", responseText);
  
      // Ch·ªâ x·ª≠ l√Ω l∆∞u chi ti√™u m·ªõi n·∫øu kh√¥ng ph·∫£i c√¢u h·ªèi t·ªïng h·ª£p
      if (!isSummaryRequest) {
        const match = responseText.match(
          /\*\*Ph√¢n lo·∫°i:\s*(.*?),\s*Ti·ªÅn:\s*([\d,.]+)\s*VNƒê,\s*Ti√™u ƒë·ªÅ:\s*(.*?)\*\*/
        );
  
        if (match) {
          const [_, category, amount, title] = match;
          try {
            await saveExpenseToCSV(user.uid, {
              category: category.trim(),
              amount: amount.replace(/[,.]|VNƒê/g, '').trim(),
              title: title.trim(),
              type: determineTransactionType(userMessage.text, category),
              timestamp: new Date().toISOString()
            });
            console.log("Successfully saved transaction to CSV");
            refreshTransactions();
          } catch (error) {
            console.error("Error saving to CSV:", error);
            Alert.alert('Error', 'Kh√¥ng th·ªÉ l∆∞u chi ti√™u. Vui l√≤ng th·ª≠ l·∫°i.');
          }
        }
      }
  
      const botResponse: Message = {
        id: (Date.now() + 1).toString(),
        text: responseText,
        isUser: false,
        timestamp: new Date(),
      };
      
      const finalMessages = [...updatedMessages, botResponse];
      setMessages(finalMessages);
      await updateChatHistory(user.uid, finalMessages);
  
    } catch (error) {
      console.error('Chat error:', error);
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        text: "Xin l·ªói, c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i sau.",
        isUser: false,
        timestamp: new Date(),
      };
      const finalMessages = [...updatedMessages, errorMessage];
      setMessages(finalMessages);
      await updateChatHistory(user.uid, finalMessages);
    } finally {
      setIsLoading(false);
    }
  };
  
  // H√†m ph·ª• tr·ª£ ƒë·ªÉ x√°c ƒë·ªãnh lo·∫°i giao d·ªãch
  const determineTransactionType = (
    message: string,
    category: string
  ): 'income' | 'expense' => {
    const incomeCategories = ['L∆∞∆°ng th√°ng', 'Ti·∫øt ki·ªám', 'Kh√°c'];
    const incomeKeywords = ['nh·∫≠n', 'ƒë∆∞·ª£c', 'cho', 't·∫∑ng', 'th∆∞·ªüng'];
    
    return incomeCategories.includes(category) ||
      incomeKeywords.some(keyword => message.toLowerCase().includes(keyword))
      ? 'income'
      : 'expense';
  };
  
  
  const toggleRecording = async (mode: 'tap' | 'hold') => {
    if (isRecording) {
      try {
        if (recordingRef.current) {
          await recordingRef.current.stopAndUnloadAsync();
          await Audio.setAudioModeAsync({
            allowsRecordingIOS: false,
            playsInSilentModeIOS: false,
          });
  
          const uri = recordingRef.current.getURI();
          if (uri) {
            const fileInfo = await FileSystem.getInfoAsync(uri);
            if (fileInfo.exists) {
              const formData = new FormData();
              const fileData: any = {
                uri: uri,
                name: 'audio.m4a',
                type: 'audio/m4a',
              };
              formData.append('file', fileData);
              formData.append('model', 'Whisper-Large-V3-Turbo');
  
              try {
                const transcriptionResponse = await fetch(
                  'https://api.groq.com/openai/v1/audio/transcriptions',
                  {
                    method: 'POST',
                    headers: {
                      'Authorization': `Bearer ${groq.apiKey}`,
                    },
                    body: formData,
                  }
                );
  
                if (!transcriptionResponse.ok) {
                  throw new Error(`HTTP error! status: ${transcriptionResponse.status}`);
                }
  
                const transcriptionData: TranscriptionResponse = await transcriptionResponse.json();
                if (transcriptionData && transcriptionData.text) {
                  await sendMessageByVoice(transcriptionData.text);
                } else {
                  throw new Error('No transcription text received');
                }
              } catch (transcriptionError) {
                console.error('Transcription error:', transcriptionError);
                Alert.alert('Error', 'Kh√¥ng th·ªÉ chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n');
              }
              await FileSystem.deleteAsync(uri, { idempotent: true });
            }
          }
        }
      } catch (err) {
        console.error('Stop recording error:', err);
        Alert.alert('Error', 'Kh√¥ng th·ªÉ x·ª≠ l√Ω ghi √¢m');
      } finally {
        recordingRef.current = null;
        setIsRecording(false);
        setRecordingMode(null);
      }
    } else {
      try {
        if (recordingRef.current) {
          await recordingRef.current.stopAndUnloadAsync();
          recordingRef.current = null;
        }
  
        const { status } = await Audio.requestPermissionsAsync();
        if (status !== 'granted') {
          Alert.alert('Permission required', 'Vui l√≤ng c·∫•p quy·ªÅn micro');
          return;
        }
  
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: true,
          playsInSilentModeIOS: true,
        });
  
        const { recording } = await Audio.Recording.createAsync(
          Audio.RecordingOptionsPresets.HIGH_QUALITY
        );
        recordingRef.current = recording;
        setIsRecording(true);
        setRecordingMode(mode);
      } catch (err) {
        console.error('Start recording error:', err);
        Alert.alert('Error', 'Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m');
        setIsRecording(false);
        setRecordingMode(null);
      }
    }
  };

  const handlePressIn = () => {
    // Start recording immediately when pressing down
    toggleRecording('hold');
  };

  const handlePressOut = async () => {
    // Stop visualizer immediately
    setIsRecording(false);
    setRecordingMode(null);

    if (recordingRef.current) {
      try {
        await recordingRef.current.stopAndUnloadAsync();
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: false,
          playsInSilentModeIOS: false,
        });

        const uri = recordingRef.current.getURI();
        if (uri) {
          const fileInfo = await FileSystem.getInfoAsync(uri);
          if (fileInfo.exists) {
            const formData = new FormData();
            const fileData: any = {
              uri: uri,
              name: 'audio.m4a',
              type: 'audio/m4a',
            };
            formData.append('file', fileData);
            formData.append('model', 'whisper-large-v3');

            try {
              const transcriptionResponse = await fetch(
                'https://api.groq.com/openai/v1/audio/transcriptions',
                {
                  method: 'POST',
                  headers: {
                    'Authorization': `Bearer ${groq.apiKey}`,
                  },
                  body: formData,
                }
              );

              if (!transcriptionResponse.ok) {
                throw new Error(`HTTP error! status: ${transcriptionResponse.status}`);
              }

              const transcriptionData: TranscriptionResponse = await transcriptionResponse.json();
              if (transcriptionData && transcriptionData.text) {
                await sendMessageByVoice(transcriptionData.text);
              } else {
                throw new Error('No transcription text received');
              }
            } catch (transcriptionError) {
              console.error('Transcription error:', transcriptionError);
              Alert.alert('Error', 'Kh√¥ng th·ªÉ chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n');
            }
            await FileSystem.deleteAsync(uri, { idempotent: true });
          }
        }
      } catch (err) {
        console.error('Stop recording error:', err);
        Alert.alert('Error', 'Kh√¥ng th·ªÉ x·ª≠ l√Ω ghi √¢m');
      } finally {
        recordingRef.current = null;
      }
    }
  };

  const captureOrPickImage = async () => {
    Alert.alert(
      'Ch·ªçn ·∫£nh',
      'B·∫°n mu·ªën ch·ª•p ·∫£nh m·ªõi hay ch·ªçn ·∫£nh c√≥ s·∫µn?',
      [
        {
          text: 'Ch·ª•p ·∫£nh',
          onPress: async () => {
            try {
              const { status } = await ImagePicker.requestCameraPermissionsAsync();
              if (status !== 'granted') {
                Alert.alert('Permission required', 'Vui l√≤ng c·∫•p quy·ªÅn truy c·∫≠p camera');
                return;
              }

              const result = await ImagePicker.launchCameraAsync({
                mediaTypes: ImagePicker.MediaTypeOptions.Images,
                quality: 1,
                allowsEditing: false,
              });

              if (!result.canceled && result.assets && result.assets.length > 0) {
                // Process image immediately after capture
                processImage(result.assets[0].uri);
              }
            } catch (error) {
              console.error('Camera error:', error);
              Alert.alert('Error', 'Kh√¥ng th·ªÉ ch·ª•p ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i.');
            }
          },
        },
        {
          text: 'Ch·ªçn ·∫£nh',
          onPress: async () => {
            try {
              const { status } = await ImagePicker.requestMediaLibraryPermissionsAsync();
              if (status !== 'granted') {
                Alert.alert('Permission required', 'Vui l√≤ng c·∫•p quy·ªÅn truy c·∫≠p th∆∞ vi·ªán ·∫£nh');
                return;
              }

              const result = await ImagePicker.launchImageLibraryAsync({
                mediaTypes: ImagePicker.MediaTypeOptions.Images,
                quality: 1,
                allowsEditing: false,
              });

              if (!result.canceled && result.assets && result.assets.length > 0) {
                // Process image immediately after selection
                processImage(result.assets[0].uri);
              }
            } catch (error) {
              console.error('Image picker error:', error);
              Alert.alert('Error', 'Kh√¥ng th·ªÉ ch·ªçn ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i.');
            }
          },
        },
        { text: 'H·ªßy', style: 'cancel' },
      ],
      { cancelable: true }
    );
  };

  const processImage = async (imageUri: string) => {
    if (!user) return;
    setIsLoading(true);
  
    // ƒê·ªãnh nghƒ©a types
    type TransactionType = 'expense' | 'income';
  
    interface ExpenseData {
      category: string;
      amount: string;
      title: string;
      type: TransactionType;
      timestamp?: string;
    }
  
    try {
      const base64Image = await FileSystem.readAsStringAsync(imageUri, {
        encoding: FileSystem.EncodingType.Base64,
      });
  
      // ƒê·∫ßu ti√™n ph√¢n t√≠ch xem ƒë√¢y l√† bill hay s·∫£n ph·∫©m ƒë∆°n l·∫ª
      const initialAnalysis = await groq.chat.completions.create({
        messages: [
          {
            role: "user",
            content: [
              {
                type: "text",
                text: "Ph√¢n t√≠ch ƒë√¢y l√† h√≥a ƒë∆°n (bill) hay m·ªôt s·∫£n ph·∫©m ƒë∆°n l·∫ª? N√≥ l√† s·∫£n ph·∫©m ƒë∆°n l·∫ª khi n√≥ ch·ªâ c√≥ m·ªôt m√≥n ƒë·ªì n√†o ƒë√≥ kh√¥ng c√≥ s·ªë ti·ªÅn thanh to√°n hay g√¨ c·∫£. Tr·∫£ l·ªùi ng·∫Øn g·ªçn: BILL ho·∫∑c PRODUCT"
              },
              {
                type: "image_url",
                image_url: {
                  url: `data:image/jpeg;base64,${base64Image}`,
                }
              }
            ]
          }
        ],
        model: "llama-3.2-90b-vision-preview",
        temperature: 0.2,
        max_tokens: 1024,
      });
  
      const imageType = initialAnalysis.choices[0]?.message?.content?.trim().toUpperCase();
  
      if (imageType === 'BILL') {
        const billAnalysis = await groq.chat.completions.create({
          messages: [
            {
              role: "user",
              content: [
                {
                  type: "text",
                  text: `Ph√¢n t√≠ch h√≥a ƒë∆°n n√†y v√† tr·∫£ v·ªÅ CH√çNH X√ÅC theo format sau (kh√¥ng th√™m b·ªõt k√Ω t·ª±):
      
      TOTAL:[t·ªïng ti·ªÅn];
      ITEMS:
      **Ph√¢n lo·∫°i:[lo·∫°i h√†ng],Ti·ªÅn:[s·ªë ti·ªÅn] VNƒê,Ti√™u ƒë·ªÅ:[t√™n m√≥n]**
      **Ph√¢n lo·∫°i:[lo·∫°i h√†ng],Ti·ªÅn:[s·ªë ti·ªÅn] VNƒê,Ti√™u ƒë·ªÅ:[t√™n m√≥n]**
      (m·ªói m√≥n m·ªôt d√≤ng);
      COMMENT:[nh·∫≠n x√©t v·ªÅ c√°c kho·∫£n chi]
      
      V√≠ d·ª•:
      TOTAL:125000;
      ITEMS:
      **Ph√¢n lo·∫°i:ƒÇn u·ªëng,Ti·ªÅn:75000 VNƒê,Ti√™u ƒë·ªÅ:C∆°m g√†**
      **Ph√¢n lo·∫°i:ƒÇn u·ªëng,Ti·ªÅn:50000 VNƒê,Ti√™u ƒë·ªÅ:Tr√† s·ªØa**;
      COMMENT:C√°c m√≥n ƒÉn c√≥ gi√° h·ª£p l√Ω, ph√π h·ª£p v·ªõi m·∫∑t b·∫±ng chung.`
                },
                {
                  type: "image_url",
                  image_url: {
                    url: `data:image/jpeg;base64,${base64Image}`,
                  }
                }
              ]
            }
          ],
          model: "llama-3.2-90b-vision-preview",
          temperature: 0.2, // Gi·∫£m temperature ƒë·ªÉ response ch√≠nh x√°c h∆°n
          max_tokens: 1024,
        });
      
        console.log('Raw response:', billAnalysis.choices[0]?.message?.content);
      
        const response = billAnalysis.choices[0]?.message?.content;
        if (response) {
          try {
            // T√°ch response theo d·∫•u ch·∫•m ph·∫©y v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
            const sections = response.split(';').map(section => section.trim());
            console.log('Sections:', sections);
      
            // Ki·ªÉm tra format t·ªïng qu√°t
            if (sections.length < 3) {
              throw new Error('Thi·∫øu th√¥ng tin trong response');
            }
      
            // X·ª≠ l√Ω t·ªïng ti·ªÅn
            const totalMatch = sections[0].match(/TOTAL:(\d+)/);
            if (!totalMatch) {
              throw new Error('Kh√¥ng t√¨m th·∫•y t·ªïng ti·ªÅn');
            }
            const totalAmount = totalMatch[1];
      
            // X·ª≠ l√Ω danh s√°ch items
            const itemsSection = sections[1];
            if (!itemsSection.startsWith('ITEMS:')) {
              throw new Error('Kh√¥ng t√¨m th·∫•y danh s√°ch m√≥n h√†ng');
            }
      
            // T√°ch v√† x·ª≠ l√Ω t·ª´ng item
            const itemMatches = itemsSection.match(/\*\*Ph√¢n lo·∫°i:.*?\*\*/g);
            if (!itemMatches) {
              throw new Error('Kh√¥ng t√¨m th·∫•y m√≥n h√†ng n√†o');
            }
      
            const savedItems = [];
            for (const itemString of itemMatches) {
              const itemMatch = itemString.match(/\*\*Ph√¢n lo·∫°i:\s*([^,]+),\s*Ti·ªÅn:\s*([\d,.\s]+)\s*VNƒê,\s*Ti√™u ƒë·ªÅ:\s*([^\*]+)\*\*/);
              if (itemMatch) {
                const [_, category, amount, title] = itemMatch;
                
                const expenseData: ExpenseData = {
                  category: category.trim(),
                  amount: amount.replace(/[,.\s]/g, ''),
                  title: title.trim(),
                  type: 'expense' as TransactionType,
                  timestamp: new Date().toISOString()
                };
      
                console.log('Saving item:', expenseData);
                
                await saveExpenseToCSV(user.uid, expenseData);
                savedItems.push(`üõçÔ∏è ${title.trim()}: ${amount.trim()} VNƒê (${category.trim()})`);
              }
            }
      
            // X·ª≠ l√Ω comment
            const commentMatch = sections[2].match(/COMMENT:(.*)/);
            if (!commentMatch) {
              throw new Error('Kh√¥ng t√¨m th·∫•y nh·∫≠n x√©t');
            }
            const comment = commentMatch[1].trim();
      
            if (savedItems.length > 0) {
              refreshTransactions();
      
              const billSummary = `üßæ ƒê√£ x·ª≠ l√Ω bill:
      
      üí∞ T·ªïng ti·ªÅn: ${totalAmount} VNƒê
      
      üìù Chi ti·∫øt c√°c m√≥n:
      ${savedItems.join('\n')}
      
      üí≠ Nh·∫≠n x√©t: ${comment}`;
      
              const botResponse: Message = {
                id: Date.now().toString(),
                text: billSummary,
                isUser: false,
                timestamp: new Date(),
              };
      
              const updatedMessages = [...messages, botResponse];
              setMessages(updatedMessages);
              await updateChatHistory(user.uid, updatedMessages);
            }
      
          } catch (error) {
            console.error('Error processing bill items:', error);
            const errorResponse: Message = {
              id: Date.now().toString(),
              text: `‚ùå L·ªói x·ª≠ l√Ω bill: ${error instanceof Error ? error.message : 'L·ªói kh√¥ng x√°c ƒë·ªãnh'}
              
      üîç Vui l√≤ng ch·ª•p l·∫°i bill r√µ r√†ng h∆°n ho·∫∑c th·ª≠ l·∫°i.`,
              isUser: false,
              timestamp: new Date(),
            };
      
            const updatedMessages = [...messages, errorResponse];
            setMessages(updatedMessages);
            await updateChatHistory(user.uid, updatedMessages);
          }
        }
      } else {
        // X·ª≠ l√Ω s·∫£n ph·∫©m ƒë∆°n l·∫ª
        const productAnalysis = await groq.chat.completions.create({
          messages: [
            {
              role: "user",
              content: [
                {
                  type: "text",
                  text: "M√¥ t·∫£ s·∫£n ph·∫©m n√†y l√† g√¨ (s√°ch/gi√†y/qu·∫ßn √°o/...)? Format: PRODUCT:[lo·∫°i s·∫£n ph·∫©m];CATEGORY:[ph√¢n lo·∫°i chi ti√™u ph√π h·ª£p]"
                },
                {
                  type: "image_url",
                  image_url: {
                    url: `data:image/jpeg;base64,${base64Image}`,
                  }
                }
              ]
            }
          ],
          model: "llama-3.2-90b-vision-preview",
          temperature: 0.5,
          max_tokens: 256,
        });
  
        console.log('Product analysis response:', productAnalysis.choices[0]?.message?.content);
  
        const productInfo = productAnalysis.choices[0]?.message?.content;
        if (productInfo) {
          try {
            const [product, category] = productInfo.split(';');
            const productType = product.split(':')[1]?.trim();
            const expenseCategory = category.split(':')[1]?.trim();
  
            console.log('Product info:', { productType, expenseCategory });
  
            if (!productType || !expenseCategory) {
              throw new Error('Kh√¥ng th·ªÉ nh·∫≠n d·∫°ng th√¥ng tin s·∫£n ph·∫©m');
            }
  
            // Hi·ªÉn th·ªã prompt ƒë·ªÉ h·ªèi gi√°
            const botQuestion: Message = {
              id: Date.now().toString(),
              text: `T√¥i th·∫•y ƒë√¢y l√† ${productType}. B·∫°n ƒë√£ mua v·ªõi gi√° bao nhi√™u? (Vui l√≤ng n√≥i gi√° ti·ªÅn)`,
              isUser: false,
              timestamp: new Date(),
            };
  
            const updatedMessages = [...messages, botQuestion];
            setMessages(updatedMessages);
            await updateChatHistory(user.uid, updatedMessages);
  
            // K√≠ch ho·∫°t ch·∫ø ƒë·ªô l·∫Øng nghe gi√° ti·ªÅn
            setAwaitingPriceInput(true);
            setTempProductInfo({
              type: productType,
              category: expenseCategory
            });
  
            console.log('Awaiting price input for:', tempProductInfo);
  
          } catch (error) {
            console.error('Error processing product:', error);
            const errorResponse: Message = {
              id: Date.now().toString(),
              text: `L·ªói x·ª≠ l√Ω s·∫£n ph·∫©m: ${error instanceof Error ? error.message : 'L·ªói kh√¥ng x√°c ƒë·ªãnh'}`,
              isUser: false,
              timestamp: new Date(),
            };
  
            const updatedMessages = [...messages, errorResponse];
            setMessages(updatedMessages);
            await updateChatHistory(user.uid, updatedMessages);
          }
        }
      }
  
    } catch (error) {
      console.error('Image processing error:', error);
      let errorMessage = "Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω ·∫£nh.";
      if (error instanceof Error) {
        errorMessage += ` Chi ti·∫øt: ${error.message}`;
      } else {
        errorMessage += " C√≥ l·ªói kh√¥ng x√°c ƒë·ªãnh x·∫£y ra.";
      }
  
      const errorResponse: Message = {
        id: Date.now().toString(),
        text: errorMessage,
        isUser: false,
        timestamp: new Date(),
      };
  
      const updatedMessages = [...messages, errorResponse];
      setMessages(updatedMessages);
      await updateChatHistory(user.uid, updatedMessages);
    } finally {
      setIsLoading(false);
    }
  };
      
      const renderVisualizer = () => {
    if (!isRecording) return null;

    return (
      <View style={styles.visualizerWrapper}>
        <View style={styles.recordingTimerContainer}>
          <Text style={styles.recordingTimer}>
            {Math.floor(recordingDuration / 60)}:{(recordingDuration % 60).toString().padStart(2, '0')}
          </Text>
        </View>
        <View style={styles.visualizerContainer}>
          {waveData.map((value, index) => (
            <Animated.View
              key={index}
              style={[
                styles.visualizerBar,
                {
                  height: 25 * value,
                  backgroundColor: `rgba(255,255,255,${0.5 + (index / waveData.length) * 0.5})`,
                  transform: [{ scaleY: value }],
                }
              ]}
            />
          ))}
        </View>
      </View>
    );
  };

  useEffect(() => {
    if (!isRecording) {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
        animationFrameId.current = undefined;
      }
      setWaveData(Array(15).fill(1));
      setRecordingDuration(0);
    }
  }, [isRecording]);

  if (isLoadingHistory) {
    return (
      <View style={styles.loadingContainer}>
        <ActivityIndicator size="large" color="#eef4f0" />
        <Text style={styles.loadingText}>ƒêang t·∫£i l·ªãch s·ª≠ chat...</Text>
      </View>
    );
  }

  return (
    <KeyboardAvoidingView
      style={styles.container}
      behavior={Platform.OS === 'ios' ? 'padding' : 'height'}
    >
      <ImageBackground
        source={require('../../../assets/images/bbgg.png')}
        style={styles.backgroundImage}
        resizeMode="cover"
      >
        <TouchableOpacity 
          onPress={() => router.back()} 
          style={styles.backButton}
        >
          <Ionicons name="chevron-back" size={24} color="#fff" />
        </TouchableOpacity>

        <View style={styles.titleContainer}>
          <Text style={styles.headerTitle}>Chatbot</Text>
        </View>

        <View style={styles.chatContainer}>
          <FlatList
            ref={flatListRef}
            data={messages}
            keyExtractor={(item) => item.id}
            renderItem={({ item }) => (
              <View
                style={[
                  styles.messageContainer,
                  item.isUser ? styles.userMessage : styles.botMessage
                ]}
              >
                <Text style={styles.messageText}>{item.text}</Text>
              </View>
            )}
            style={styles.messagesList}
            contentContainerStyle={{ 
              paddingBottom: 16,
              flexGrow: 1,
            }}
            onContentSizeChange={() => {
              flatListRef.current?.scrollToEnd();
            }}
          />
        </View>

        <View style={styles.bottomSheetContainer}>
          <View style={styles.bottomBox}>
            {isRecording && renderVisualizer()}
            <View style={styles.actionContainer}>
              <TouchableOpacity onPress={captureOrPickImage} style={styles.iconButton}>
                <EvilIcons name="camera" size={24} color="#fff" />
              </TouchableOpacity>

              <TouchableOpacity
                onPressIn={handlePressIn}
                onPressOut={handlePressOut}
                style={[
                  styles.micButton,
                  isRecording && styles.micButtonRecording
                ]}
              >
                <Ionicons
                  name={isRecording ? "mic" : "mic-outline"}
                  size={32}
                  color="#fff"
                />
              </TouchableOpacity>

              <TouchableOpacity style={styles.iconButton}>
                <EvilIcons name="close" size={24} color="#fff" />
              </TouchableOpacity>
            </View>
          </View>
        </View>
      </ImageBackground>
    </KeyboardAvoidingView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1
  },
  backgroundImage: {
    flex: 1,
    backgroundColor: '#000'
  },
  backButton: {
    position: 'absolute',
    top: Platform.OS === 'ios' ? 50 : 30,
    left: 16,
    padding: 8,
    zIndex: 10,
  },
  titleContainer: {
    position: 'absolute',
    top: Platform.OS === 'ios' ? 50 : 30,
    left: 0,
    right: 0,
    alignItems: 'center',
    paddingVertical: 8,
  },
  headerTitle: {
    color: '#fff',
    fontSize: 18,
    fontWeight: '600',
  },
  chatContainer: {
    flex: 1,
    marginTop: 90,
    marginHorizontal: 16,
    marginBottom: 140,
    paddingBottom: 16,
  },
  messagesList: {
    flex: 1
  },
  messageContainer: {
    maxWidth: '80%',
    padding: 12,
    borderRadius: 16,
    marginVertical: 4
  },
  userMessage: {
    alignSelf: 'flex-end',
    backgroundColor: '#1d1c55'
  },
  botMessage: {
    alignSelf: 'flex-start',
    backgroundColor: '#0e0b27'
  },
  messageText: {
    color: '#fff',
    fontSize: 16
  },
  bottomBox: {
    backgroundColor: '#121217',
    borderRadius: 20,
    paddingVertical: 16,
    paddingHorizontal: 8,
    marginBottom: 8,
  },
  actionContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    paddingHorizontal: 16,
  },
  iconButton: {
    width: 48,
    height: 48,
    borderRadius: 24,
    backgroundColor: 'rgba(255,255,255,0.15)',
    justifyContent: 'center',
    alignItems: 'center'
  },
  micButton: {
    width: 64,
    height: 64,
    borderRadius: 32,
    backgroundColor: '#000001',
    justifyContent: 'center',
    alignItems: 'center'
  },
  micButtonRecording: {
    backgroundColor: '#ff4757',
  },
  visualizerWrapper: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    marginBottom: 16,
    paddingHorizontal: 16,
    height: 60,
  },
  visualizerContainer: {
    flex: 1,
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    height: 40,
    marginLeft: 16,
    marginRight: 8,
    overflow: 'hidden',
  },
  visualizerBar: {
    width: 4,
    borderRadius: 2,
    backgroundColor: 'rgba(255,255,255,0.8)',
    marginHorizontal: 1,
  },
  recordingTimerContainer: {
    minWidth: 60,
    paddingRight: 16,
  },
  recordingTimer: {
    color: '#fff',
    fontSize: 16,
    fontWeight: '500',
  },
  loadingContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: '#000',
  },
  loadingText: {
    marginTop: 8,
    fontSize: 16,
    color: '#fff'
  },
  bottomSheetContainer: {
    position: 'absolute',
    bottom: 0,
    left: 0,
    right: 0,
    padding: 16,
    paddingBottom: 8,
  },
  tapModeText: {
    color: '#fff',
    fontSize: 12,
    marginTop: 4,
    textAlign: 'center',
  },
});

export default Chatbot;